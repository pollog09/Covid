{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QWodw1CA7VsC"
   },
   "source": [
    "### Herramientas recomendadas\n",
    "- **PyTorch**: Framework para el desarrollo de redes neuronales.\n",
    "- **Weights and Biases**: Herramienta para monitoreo y visualización de métricas de entrenamiento.\n",
    "- **Google Colab**: Si no cuentan con GPU local, pueden usar Google Colab para ejecutar el proyecto. [Guía completa para conectar Google Drive a Google Colab](https://medium.com/@DataScience-ProF/a-comprehensive-guide-to-connecting-google-drive-to-google-colab).\n",
    "- **OpenCV**: Para aplicar filtros de imagen y otras transformaciones.\n",
    "\n",
    "---\n",
    "\n",
    "### Pasos a seguir\n",
    "En síntesis, el trabajo incluye: los estudiantes deben realizar clasificadores CNN utilizando el dataset **Covid-19 Image Dataset**, el cual contiene imágenes de rayos X y está clasificado en tres clases: **Covid-19**, **Normal**, y **Neumonía**.\n",
    "\n",
    "#### 4.1 Selección del modelo\n",
    "1. Seleccionen dos modelos de convolución preexistentes como **ResNet**, **AlexNet**, **VGG16**, o cualquiera de los conversados en clase.\n",
    "2. Descarguen el modelo preentrenado y realicen **fine-tuning** para adaptarlo al problema.\n",
    "3. Justifiquen la elección de ambos modelos.\n",
    "\n",
    "#### 4.2 Preprocesamiento de imágenes\n",
    "Entrenen los modelos utilizando tres conjuntos de datos diferentes:\n",
    "- **Conjunto 1**: Usar las imágenes tal como están (crudas/raw).\n",
    "- **Conjunto 2**: Aplicar un filtro bilateral para suavizar la imagen y eliminar el ruido.\n",
    "- **Conjunto 3**: Aplicar un filtro **Canny Edge** para detectar los bordes de las imágenes.\n",
    "\n",
    "> **Consejo**: Es recomendable realizar el preprocesamiento de filtros antes del entrenamiento para hacer un uso eficiente del poder computacional.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descarga del Dataset de Covid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 401
    },
    "id": "z1V5qR-Wlw0F",
    "outputId": "35ff68fd-693e-4743-d630-01be252a5b40"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset successfully moved to: dataset\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "import shutil\n",
    "\n",
    "\n",
    "# Download the dataset (default download path will be in /root/.kagglehub)\n",
    "path = kagglehub.dataset_download(\"pranavraikokte/covid19-image-dataset\")\n",
    "\n",
    "# Specify the destination path in Google Drive\n",
    "save_path = \"dataset\"\n",
    "\n",
    "# Move the downloaded dataset to the specified path in Google Drive\n",
    "shutil.move(path, save_path)\n",
    "\n",
    "print(\"Dataset successfully moved to:\", save_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparando Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WnJsOLYxcgl2",
    "outputId": "2567cac5-bc1e-42d1-d052-b65a22a046f8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
      "100%|██████████| 44.7M/44.7M [00:00<00:00, 209MB/s]\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n",
      "100%|██████████| 528M/528M [00:08<00:00, 67.3MB/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models, transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from PIL import Image\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Dataset class\n",
    "class CovidDataset(Dataset):\n",
    "    def __init__(self, image_dir, transform=None):\n",
    "        self.image_dir = image_dir\n",
    "        self.transform = transform\n",
    "        self.image_paths = []\n",
    "        self.labels = []\n",
    "\n",
    "\n",
    "# Define transformations\n",
    "data_transforms = {\n",
    "    'raw': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "# Load pre-trained models\n",
    "model_resnet = models.resnet18(pretrained=True).to(device)\n",
    "num_ftrs = model_resnet.fc.in_features\n",
    "model_resnet.fc = nn.Linear(num_ftrs, 3).to(device)  # 3 output classes\n",
    "\n",
    "model_vgg = models.vgg16(pretrained=True).to(device)\n",
    "model_vgg.classifier[6] = nn.Linear(4096, 3).to(device) # 3 output classes\n",
    "\n",
    "# Freeze the pre-trained layers\n",
    "for param in model_resnet.parameters():\n",
    "    param.requires_grad = False\n",
    "for param in model_vgg.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparando el Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "1_5i6iESsE7Z"
   },
   "outputs": [],
   "source": [
    "class CovidDataset(Dataset):\n",
    "    def __init__(self, image_dir, transform=None):\n",
    "        self.image_dir = image_dir\n",
    "        self.transform = transform\n",
    "        self.image_paths = []\n",
    "        self.labels = []\n",
    "        self.class_names = ['covid', 'normal', 'pneumonia']\n",
    "\n",
    "        # Iterate through each class folder and append file paths and labels\n",
    "        for idx, class_name in enumerate(self.class_names):\n",
    "            class_dir = os.path.join(image_dir, class_name)\n",
    "            for img_file in os.listdir(class_dir):\n",
    "                self.image_paths.append(os.path.join(class_dir, img_file))\n",
    "                self.labels.append(idx)  # Assign label based on class index\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        # Read image using PIL\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8ZAVo_lgsl2K"
   },
   "source": [
    "# Resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 332
    },
    "id": "MUvs5gIqsmCj",
    "outputId": "810ac3bb-12f8-44db-b8e2-e00242ad6c04"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'CovidDataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m val_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/content/drive/MyDrive/Covid19_Image_Dataset/test\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Datasets\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mCovidDataset\u001b[49m(image_dir\u001b[38;5;241m=\u001b[39mdataset_dir, transform\u001b[38;5;241m=\u001b[39mdata_transforms[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraw\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m      7\u001b[0m val_dataset \u001b[38;5;241m=\u001b[39m CovidDataset(image_dir\u001b[38;5;241m=\u001b[39mval_dir, transform\u001b[38;5;241m=\u001b[39mdata_transforms[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraw\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# DataLoaders\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'CovidDataset' is not defined"
     ]
    }
   ],
   "source": [
    "# Paths\n",
    "dataset_dir = \"/content/drive/MyDrive/Covid19_Image_Dataset/train\"  # Update with your actual paths\n",
    "val_dir = \"/content/drive/MyDrive/Covid19_Image_Dataset/test\"\n",
    "\n",
    "# Datasets\n",
    "train_dataset = CovidDataset(image_dir=dataset_dir, transform=data_transforms['raw'])\n",
    "val_dataset = CovidDataset(image_dir=val_dir, transform=data_transforms['raw'])\n",
    "                                                                  \n",
    "# DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGG"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
